---
title: "My Datafabric QnA Assistent"
date: 2025-06-25T18:07:49+12:00
draft: false
---


I have developed my agent system (using Google's ADK - Agent Development Kit) designed to answer questions related to "data fabric" concepts.
It leverages a ~local database (DuckDB)~ and an external web search agent for information retrieval.
This code is a good starting point, but prompt engineering, especially around the data extracted from the local DB, will make a huge difference in its performance.

** Agents
{{< figure src="images/Screenshot_2025-06-25_165928.jpg" alt="Agent flow" >}}

- =retrieves_contents= can be used for datafabric concepts.
- =websearch_agent= can be used in other contexts.

Example Use Case:

Imagine the user asks: "What are the minimum hardware requirements for EDF installation?".

1.  The =root_agent= receives the question.
2.  Following its instructions, it calls =retrieves_contents("minimum hardware requirements for EDF installation", 5)=.
3.  =retrieves_contents= queries the DuckDB database using full-text search.
4.  If relevant results are found in the database, =retrieves_contents= returns them to the =root_agent=. The =root_agent= would ideally use those results to formulate an answer.
5.  If =retrieves_contents= finds nothing, the =root_agent= then calls the =websearch_agent=.
6.  The =websearch_agent= performs a Google search using the same or similar keywords.
7.  The =websearch_agent= returns the search results to the =root_agent=.
8.  The =root_agent= then uses the search results from the web or the DuckDB results to generate an answer for the user (ideally using the LLM to summarize and synthesize the information).
  
** UI
ADK Web UI can be used for Integrative QnA Assistant.
{{< figure src="images/Screenshot_2025-06-25_172518.jpg" alt="ADK UI" >}}
** Pros

-   *Modular Design:* The use of agents and tools promotes a modular and reusable design.  
-   *Hybrid Information Retrieval:*  Combines local database search (DuckDB) with web search, providing a comprehensive approach to answering questions.
-   *Clear Agent Instructions:* The =instruction= strings for both agents are relatively clear, guiding their behavior.
-   *DuckDB Integration:*  DuckDB is a fast and efficient in-process database, suitable for analytical queries.
-   *Error Handling:* The =retrieves_contents= function includes basic error handling for empty results and empty keywords.
-   *Tool Orchestration:* The =root_agent='s instruction to use =websearch_agent= when =retrieves_contents= fails demonstrates a basic form of tool orchestration.

** Cons
-   *Dependency on ADK (or similar):* The code is tightly coupled to the Google ADK framework. This might limit portability to other environments.
-   *Limited Error Handling:* The error handling in =retrieves_contents= is basic. More robust error handling 
-   *Hardcoded Database Name:* The database name ("edf_manual.duckdb") is hardcoded in =retrieves_contents=. This makes the function less flexible.  will consider making it a parameter.
-   *Limited Context Passing:* The =root_agent= passes only keywords to =retrieves_contents= passing the full question context. This could limit the effectiveness of the local database search.
-   *String Concatenation of Results:* The =retrieves_contents= function concatenates all text results with newlines. This is a simple approach, but it might not be ideal for all use cases. will consider a structured output (e.g., a list of dictionaries) might be more useful.
-   *Lack of Fine-grained Control over Web Search:* The code relies on the =google_search= tool, which might not offer fine-grained control over search parameters (e.g., date ranges, specific websites).
-   *No Prompt Engineering for =retrieves_contents=:* The code directly returns the text from the DuckDB results.  It doesn't use the LLM to synthesize or summarize the information. Prompting around the results of the local db search would likely yield much better responses.

* Run 
#+begin_src bash
  $ python -m venv .venv
  $ .venv/bin/activate

  # python dependency
  $ pip install google-adk
  $ pip install duckdb

  # duckdb 
  $ curl https://install.duckdb.org | sh

  #start ADK web UI to run and test
  $ adk web
#+end_src

* Code
#+begin_src python
  from google.adk.agents import Agent

  from google.adk.tools.agent_tool import AgentTool
  from google.adk.tools import google_search

  import duckdb

  WEBSEARCH_PROMPT = """
  Role: You are a highly accurate AI assistant specialized in factual retrieval using available tools. 
  Your primary task is searching keywords in case you cannot know 

  Tool: You MUST utilize the Google Search tool to gather the most current information. 

  Objective: The primary goal is to find at least 10 distinct informationc 
  """

  websearch_agent = Agent(
      model="gemini-2.0-flash",
      name="websearch_agent",
      instruction=WEBSEARCH_PROMPT,
      output_key="result_contents",
      tools=[google_search],
  )


  def retrieves_contents(keywd : str, top_n : int ) -> dict:
      """Retrieves the related contents about data-fabric (mapr, datafabric, EDF, DF, hadoop, mfs) from vector database.

      Args:
          keywd (str): The keyword to search against vector database.
          top_n (int): the number of searched contents, at least 5

      Returns:
          dict: status and result or error msg.
      """


      con = duckdb.connect("edf_manual.duckdb")

      result = con.sql(f""" with fts as (
         select *, fts_main_edf_manual_tab.match_bm25(
             page,
             '{keywd}',
              fields := 'text'
         ) as score
         from edf_manual_tab
       )
     select score, text
     from fts
     where score is not null
     order by score desc
     limit {top_n}""")

      
      ### error handler
      if len(result.df()) < 1:
          return {
              "status": "error",
              "error_message": f"There is no returned contents.",
          }


      if (len(keywd) < 1) :
          return {
              "status": "error",
              "error_message": f"There is no keywords to search.",
          }

      return {
              "status": "success",
              "result": "\n".join(result.df()['text']),
      }


  root_agent = Agent(
      name="data_fabric_QA_agent",
      model="gemini-2.0-flash",
      description=(
          "Agent to retrieves contents about the related contents about data-fabric (mapr, datafabric, EDF, DF, hadoop, mfs)."
      ),
      instruction=(
          "You are a helpful agent who can retrieves contents about questions about data-fabric, mapr, datafabric, edf, hadoop"
          "You will be given word list, ex) 'installation'"
          "You must call tool, retrieves_contents with args like: retrieves_contents('installation', 5)"
          "If you cannot search anything with retrieves_contents, use the websearch_agent"
      ),
      tools=[retrieves_contents, AgentTool(agent=websearch_agent),],
  )
#+end_src

** Code Description
Here's a step-by-step explanation:

1.  *Imports:*
    *   =google.adk.agents.Agent=:  Imports the =Agent= class, the fundamental building block for creating agents in the ADK framework.
    *   =google.adk.tools.agent_tool.AgentTool=: Imports =AgentTool=, used to wrap other agents and make them callable as tools within a larger agent system.
    *   =google.adk.tools.google_search=: Imports =google_search=, presumably a pre-built tool to perform Google searches.
    *   =duckdb=: Imports the DuckDB library, an in-process analytical database.

2.  *=websearch_agent= Definition:*
    *   =WEBSEARCH_PROMPT=: Defines a string containing instructions for the =websearch_agent=.  This prompt outlines its role as a factual retrieval assistant that /must/ use Google Search to find current information and gather at least 10 distinct pieces of information.  The =output_key= is set to =recent_citing_papers=, which seems like a misnomer because this agent searches the web using keywords, so something like 'search_results' would be more appropriate.
    *   =websearch_agent=: Creates an =Agent= instance named =websearch_agent=.
        *   =model= "gemini-2.0-flash":  Specifies the language model to be used (likely a fast version of Google's Gemini model).
        *   =name= "websearch_agent": Sets the name of the agent.
        *   =instruction=WEBSEARCH_PROMPT=:  Assigns the prompt defined earlier.
        *   =tools=[google_search]:  Provides the Google Search tool to the agent.

3.  *=retrieves_contents= Function:*
    *   This function is designed to query a DuckDB database (named "edf_manual.duckdb") to retrieve content related to data fabric concepts.
    *   It takes a =keywd= (keyword) and =top_n= (number of results) as input.
    *   It uses DuckDB's full-text search (FTS) capabilities (=fts_main_edf_manual_tab.match_bm25=) to find relevant entries in the =edf_manual_tab= table based on the =page= column.  It uses a score to rank its results.
    *   The query filters results where the FTS score is not null and orders them by score in descending order, limiting the output to =top_n= results.
    *   Error handling: It checks for empty results or empty keywords and returns an error message if either is true.
    *   The function returns a dictionary containing either a "success" status with the concatenated text from the search results or an "error" status with an error message.

4.  *=root_agent= Definition:*
    *   =root_agent=: Creates the main =Agent= instance named =data_fabric_QA_agent=.
        *   =name= data_fabric_QA_agent: Sets the name of the agent.
        *   =model= gemini-2.0-flash: Specifies the language model.
        *   =description=: Provides a description of the agent's purpose.
        *   =instruction=:  Provides instructions for the agent. Key points:
            *   It's designed to answer questions about data fabric, MapR, EDF, and Hadoop.
            *   It's expected to use the =retrieves_contents= tool with keywords.
            *   If =retrieves_contents= returns no results, it should use the =websearch_agent=.
        *   =tools=[retrieves_contents, AgentTool(agent=websearch_agent)]: Provides the agent with two tools: the =retrieves_contents= function and the =websearch_agent= (wrapped in =AgentTool= to be used as a callable tool).


** Potential Improvements
-   *Abstract Database Access:*  Create a class or interface to abstract the database access logic, making it easier to switch to a different database in the future.
-   *Improve Error Handling:* Add more comprehensive error handling to the =retrieves_contents= function.
-   *Parameterize Database Name:* Make the database name a parameter to the =retrieves_contents= function.
-   *Pass Full Question Context:*  Pass the full question context to =retrieves_contents= to improve search relevance.
-   *Structured Output:*  Return a structured output (e.g., a list of dictionaries) from =retrieves_contents= instead of concatenating the text.
-   *Add Search Parameters:* If possible, expose more search parameters for the =google_search= tool.
-   *Implement Prompt Engineering:* Use the LLM to synthesize and summarize the information retrieved from both DuckDB and the web search. This is crucial for generating coherent and useful answers.
-   *Implement Logging:* Add logging to track agent behavior and debug issues.
-   *Add Unit Tests:* Write unit tests to ensure the code functions correctly.

* Local Database (DUCKDB)
DuckDB is a fantastic embedded analytical database, known for its speed and ease of use.
One of its powerful features is built-in support for Full-Text Search (FTS). we'll walk through how to leverage FTS in DuckDB to efficiently search text data.

- What is the *Full-Text Search*?
  Traditional `LIKE` queries in SQL can be slow and inefficient for large text datasets.
  FTS provides a much faster and more relevant way to search through text, using indexing and ranking algorithms to find the best matches for your queries.

DuckDB's built-in FTS capabilities make it easy to add powerful text search functionality to your data analysis workflows.
By using `pragma create_fts_index` and the `match_bm25` function, you can quickly search and retrieve relevant information from large text datasets.

- *BM25*:  A popular ranking function that considers both the frequency of the search terms in a document and the length of the document.

You can explore further by customizing the ranking algorithm, adding stemming or stop word removal, and indexing multiple columns.

https://motherduck.com/blog/search-using-duckdb-part-3/


** Explore the duckdb FTS
1. *Table Creation and Inspection*:
   * Creates a table named `edf_install_tab` by importing data from the CSV file `./installation_db.csv`.  This is equivalent to `CREATE TABLE edf_install_tab AS SELECT * FROM read_csv_auto('./installation_db.csv');`.
   * `DESCRIBE edf_install_tab`:  This SQL command shows the schema of the `edf_install_tab` table, specifically the `column_name` and `column_type`. The results shows that the column `text` from the csv file has been loaded into the table as a VARCHAR.

2. *Full-Text Search Index Creation*:
   * `pragma create_fts_index(edf_install_tab, text, text)`: This is the core of the code. It creates a Full-Text Search (FTS) index on the `edf_install_tab` table.
     * `edf_install_tab`: Specifies the table to index.
     * `text`:  Specifies the column to index (the 'text' column). The second `text` parameter is probably redundant, the SQL query executes the same way without it.
   * The `pragma` statement automatically creates several hidden tables that support the FTS index. This is why you see tables like `dict`, `docs`, `fields`, `stats`, `stopwords`, and `terms` under the schema `fts_main_edf_install_tab` when running `show all tables`.

3. *Table Listing:*
   * `select database, schema, name, column_names FROM (show all tables);`: This query lists all tables in the database, including the FTS index tables created by the `pragma` statement.  It shows the database name, schema, table name, and the columns of each table.  This allows us to see the tables generated by the FTS index.

4. *Full-Text Search Query*:
   * The `WITH` clause defines a Common Table Expression (CTE) named `fts`.
   * `fts_main_edf_install_tab.match_bm25(...)`:  This is the function that performs the full-text search.  It uses the BM25 ranking algorithm (a popular ranking function for search).
     * `text`: This is the column to search in.
     * `'minimum requirement of hardware disk space'`:  This is the search query string.
     * `fields := 'text'`:  Specifies that we are searching within the 'text' field.
   * The `SELECT score, text ...` query then selects the `score` (relevance) and the `text` from the `fts` CTE.
   * `WHERE score IS NOT NULL`: Filters the results to only include matches (where the score is not null).
   * `ORDER BY score DESC`: Orders the results by score in descending order (highest score first).
   * `LIMIT 5`:  Limits the results to the top 5 matches.

     This query does the following:
    * Calculate a `score` representing the relevance of each text to the search query, using the BM25 ranking algorithm.
    * Select the `score` and `text` for matching rows.
    * Filters rows without a score.
    * Orders rows by score in descending order and limits the result set to the top 5 matches.


#+begin_src db
  $ duckdb edf_test.duck
  > select * from './installation_db.csv';

  > create table edf_install_tab as select * from './installation_db.csv';

  > describe edf_install_tab;
┌─────────────┬─────────────┬─────────┬─────────┬─────────┬─────────┐
│ column_name │ column_type │  null   │   key   │ default │  extra  │
│   varchar   │   varchar   │ varchar │ varchar │ varchar │ varchar │
├─────────────┼─────────────┼─────────┼─────────┼─────────┼─────────┤
│ text        │ VARCHAR     │ YES     │ NULL    │ NULL    │ NULL    │
└─────────────┴─────────────┴─────────┴─────────┴─────────┴─────────┘

  > select * from edf_install_tab limit 10;
┌──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                                                         text                                                         │
│                                                       varchar                                                        │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│ Possible Cause\nSolution\nThe Container for Developers is setup with only users mapr and root . Y ou are running a…  │
│ The objective of a cluster plan is to detail each node's set of services.\nThis section describes some of the serv…  │
│ While the Data Fabric is relatively easy to install and administer, designing and tuning a large production MapRed…  │
│ For a high availability cluster, use five (5) ZooKeepers, so that the cluster can tolerate two (2) ZooKeeper nodes…  │
│ Note these special considerations for clusters of 10 nodes or fewer:\n- · Erasure coding and rolling updates are n…  │
│ - · Dual CPU socket system board\n- · 2x8 core CPU, 32 cores with HT enabled\n- · 8x8GB DIMMs, 64GB RAM (DIMM coun…  │
│ On medium clusters, the performance demands of the CLDB and ZooKeeper services require them to be assigned to sepa…  │
│ HPE Ezmeral Data Fabric Monitoring Architecture on page 1696\nHPE Ezmeral Data Fabric Monitoring integrates with o…  │
│ When you configure replication for HPE Ezmeral Data Fabric Database tables, the HBase client is not required by de…  │
│ The topic includes example cluster designs for 6-node, 12-node, and 50-node clusters:\n- · Example 1: 6-Node Clust…  │
├──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤
│                                                       10 rows                                                        │
└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘

  > pragma create_fts_index(edf_install_tab, text, text);

  > select database, schema, name, column_names FROM (show all tables);
┌─────────────┬──────────────────────────┬─────────────────┬──────────────────────────┐
│  database   │          schema          │      name       │       column_names       │
│   varchar   │         varchar          │     varchar     │        varchar[]         │
├─────────────┼──────────────────────────┼─────────────────┼──────────────────────────┤
│ edf_text_db │ fts_main_edf_install_tab │ dict            │ [termid, term, df]       │
│ edf_text_db │ fts_main_edf_install_tab │ docs            │ [docid, name, len]       │
│ edf_text_db │ fts_main_edf_install_tab │ fields          │ [fieldid, field]         │
│ edf_text_db │ fts_main_edf_install_tab │ stats           │ [num_docs, avgdl]        │
│ edf_text_db │ fts_main_edf_install_tab │ stopwords       │ [sw]                     │
│ edf_text_db │ fts_main_edf_install_tab │ terms           │ [docid, fieldid, termid] │
│ edf_text_db │ main                     │ edf_install_tab │ [section, text]          │
└─────────────┴──────────────────────────┴─────────────────┴──────────────────────────┘

 > with fts as (
    select *, fts_main_edf_install_tab.match_bm25(
        text,
        'minimum requirement of hardware disk space',
         fields := 'text'
    ) as score
    from edf_install_tab
  )         
  select score, text
  from fts
  where score is not null
  order by score desc
  limit 5;

┌────────────────────┬─────────────────────────────────────────────────────────────────────────────────────────────────┐
│       score        │                                              text                                               │
│       double       │                                             varchar                                             │
├────────────────────┼─────────────────────────────────────────────────────────────────────────────────────────────────┤
│  6.357794621524219 │ ```\n$ free -g total        used        free      shared      buffers cached Mem:            …  │
│  5.411406659513965 │ For a high availability cluster, use five (5) ZooKeepers, so that the cluster can tolerate tw…  │
│ 5.2460930004896165 │ Note these special considerations for clusters of 10 nodes or fewer:\n- · Erasure coding and …  │
│  5.244083613354042 │ ```\nhadoop distcp hdfs://nn1:8020/user/sara/file.txt file:///hdfsmount/user/ sara\n```\n- 3.…  │
│ 5.1089523643929216 │ - · SUSE Linux Enterprise Server 15 SP3 Upgrade Guide\n- · SUSE Linux Enterprise Server 15 SP…  │
└────────────────────┴─────────────────────────────────────────────────────────────────────────────────────────────────┘
#+end_src
