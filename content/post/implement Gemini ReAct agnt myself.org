---
title: "Implement Gemini ReAct Agnt Myself"
date: 2025-01-28T11:34:04+13:00
draft: false
---

The best way to understand any technical concept is to implement it myself. Luckily, I found a wonderful [[https://www.youtube.com/watch?v=hKVhRA9kfeMvideo][Youtube Video]] which is implementing a _ReAct_ agent. Shortly, we need to force LLM to run in a loop of ~Thought~, ~Action~, ~PAUSE~, ~Observation~ unless it find a correct ~Answer~ of user query.

The code in the video, originally, used the llama3-70b-8192 but I implemented with Gemini to learn myself. While I was doing it, interestingly, I found that there is something different between Gemini and llama3, when process ~ChatMessage~. For some reason, the message's =_str_= looks different.


* pip install
#+begin_src bash
  pip install llama-index
  pip install llama-index-llms-gemini
#+end_src

* Implement
99% same with original post, but be careful when you process the ~ChatMessage~ in Gemini. Specially, when you process the _assistant_ messages, for unknown reason, you need to use =str= function.
#+begin_src python
  import os
  from llama_index.llms.gemini import Gemini
  from llama_index.core.llms import ChatMessage

  os.environ["GOOGLE_API_KEY"]= ".."
  llm = Gemini(model="models/gemini-1.5-flash",)

  class Agent:
      def __init__(self, client: Gemini, system: str="") -> None:
          self.client = client
          self.system = system
          self.messages: list = []
          if self.system :
              self.messages.append(ChatMessage(role="system", content=system))

      def __call__(self, message=""):
          if message:
              self.messages.append(ChatMessage(role="user", content=message))
          result = self.execute()
          self.messages.append(ChatMessage(role="assistant", content=str(result)))
          return result

      def execute(self):
          result = self.client.chat(self.messages)
          return result


  system_prompt = '''
  You run in a loop of Thought, Action, PAUSE, Observation.
  At the end of the loop you output an Answer
  Use Thought to describe your thoughts about the question you have been asked.
  Use Action to run one of the actions available to you - then return PAUSE.
  Observation will be the result of running those actions.

  Your available actions are:

  calculate:
  e.g. calculate: 4 * 7 / 3
  Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary

  get_planet_mass:
  e.g. get_planet_mass: Earth
  returns weight of the planet in kg

  Example session:

  Question: What is the mass of Earth times 2?
  Thought: I need to find the mass of Earth
  Action: get_planet_mass: Earth
  PAUSE 

  You will be called again with this:

  Observation: 5.972e24

  Thought: I need to multiply this by 2
  Action: calculate: 5.972e24 * 2
  PAUSE

  You will be called again with this: 

  Observation: 1,1944×10e25

  If you have the answer, output it as the Answer.

  Answer: The mass of Earth times 2 is 1,1944×10e25.
  '''.strip()

  def calculate(operation: str) -> float:
      return eval(operation)


  def get_planet_mass(planet) -> float:
      if planet == "earth":
          return 5.972e24
      if planet == "mars":
          return 6.39e23
      if planet == "jupiter":
          return 1.898e27
      if planet == "saturn":
          return 5.683e26
      if planet == "uranus":
          return 8.681e25
      if planet == "neptune":
          return 1.024e26
      if planet == "mercury":
          return 3.285e23
      if planet == "venus":
          return 4.867e24
      return None
#+end_src
- The Agent class initializes with a Gemini client and an optional system message.
- The __call__ method appends user messages and calls the execute method.
- The execute method sends the messages to the Gemini client and returns the result.
- A detailed system prompt is defined to guide the agent's behavior. *(Key Messages for system to act ReACT)*
 

* ReAct Loop

#+begin_src python
  def loop (max_iteration=10, query: str = ""):
      neil_tyson = Agent(client=llm, system=system_prompt)
      tools = ["calculate", "get_planet_mass"]
      next_prompt = query
      i = 0
      while i < max_iteration:
          print(f"try run '{i}'")
          i += 1
          result = neil_tyson(next_prompt)
          print (result)

          if "PAUSE" in result and "Action" in result:
              action = re.findall(r"Action: ([a-z_]+): (.+)", result, re.IGNORECASE)
              chosen_tool = action[0][0]
              arg = acton[0][1]

              if chosen_tool in tools:
                  result_tool = eval(f"{chosen_tool}('{arg}')")
                  next_prompt = f"Observation: {result_tool}"
              else :
                  next_prompt = f"Observation: Tool not found"
              print(next_prompt)
              continue
          if "Answer" in str(result):
              print("matched Answer")
              break

  loop(query="What is the mass of Earth plus the mass of Saturn and all of that times 2?")
#+end_src

- The loop function runs the agent in a loop, processing the query and handling actions.
- It uses regular expressions to extract actions and arguments from the agent's response.
- The loop continues until an answer is found or the maximum iterations are reached.


* Security Issue
This code uses ~eval~ function. Avoid using eval for untrusted input to prevent security risks. Consider using safer alternatives.
