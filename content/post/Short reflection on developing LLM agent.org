---
title: "Short Reflection on Developing LLM Agent"
date: 2025-07-02T15:30:37+12:00
draft: false
---

Self training myself on LLM Agent. Surely, Agent's relying on LLM and even an exact same query generates different results based on LLM.
It's not sure that this is a LLM issue or Prompt. I know that same LLM can produce various output based on Prompts.

To get more consistent results from an LLM agent:
1. *Refine Prompts:* Experiment with more specific, unambiguous prompts.
2. *Control LLM Parameters:* Adjust temperature (lower for more deterministic output) and top\_p.
3. *Implement a Validation Layer:* Add a system to evaluate and filter outputs based on predefined criteria.
4. *Few-Shot Learning:* Provide examples in your prompts to guide the LLM's response.
5. *Ensemble Methods:* Use multiple LLM calls and aggregate/validate the results.
6. *Provide Context*: Provide background context about the query as you can. 
It sounds like that English is the best coding language in the LLM agents world, and there must be a lot of costs for the iterative test to achieve the qualified results. It doesn't matter with developing tools.

So far only what I can do is as my little tip is pouring overall knowledge as you can do and be specific and restrict the output result as prompt.

Or you may give away the same result from different LLM. Up to your production, once you decide it, keep it and strive to iteratively improve the quality of my responses. You should bring up your baby (LLM agent)
